{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and camera calibration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import cv2 \n",
    "import pickle\n",
    "import glob\n",
    "#from scipy.misc import imread, imresize\n",
    "from skimage.transform import resize\n",
    "from sklearn.linear_model import (\n",
    "    LinearRegression, TheilSenRegressor, RANSACRegressor, HuberRegressor)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "#file_name = 'calibration.p'\n",
    "file_name = 'Camera_Calibration/Mobius_Dashcam_Camera_Cal/1920x1080/mobius_dashcam_1920x1080_calibration.p'\n",
    "\n",
    "with open(file_name, 'rb') as f:   \n",
    "    mtx, dist = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def draw_viewing_window(image,viewing_window):\n",
    "    \"\"\"\n",
    "    Draws viewing window onto a copy of an image\n",
    "    \n",
    "    @param image:          input image\n",
    "    @param viewing_window: List of four 1x4 numpy arrays: left_line, top_line, right_line, bottom_line. \n",
    "    Each numpy array represents one of the four lines of the polygon that defines the viewing window. \n",
    "    Each numpy array contains four numbers: x1, y1, x2, y2. (x1, y1) is the starting coordinate of the \n",
    "    line. (x2, y2) is the ending coordinate of the line. \n",
    "    \n",
    "    @result image_copy: resulting image with viewing window drawn on a copy of the input image\n",
    "    \n",
    "    \"\"\"\n",
    "    image_copy = np.copy(image)\n",
    "    for line in viewing_window:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            # Draw the line onto image_copy \n",
    "            cv2.line(image_copy,(x1,y1),(x2,y2),(0,255,0),10)\n",
    "    return image_copy\n",
    "\n",
    "# Makes the viewwing window which is used by draw_viewing_window()\n",
    "def make_viewing_window(bottom_left,top_left,top_right,bottom_right):\n",
    "    \"\"\"\n",
    "    Makes the viewing window that is used by draw_viewing_window()\n",
    "    \n",
    "    @param bottom_left:     A two-element list or tuple containing the (x,y) coordinate of the bottom left point \n",
    "    of the viewing window\n",
    "    @param top_left:        A two-element list or tuple containing the (x,y) coordinate of the top left point of \n",
    "    the viewing window\n",
    "    @param top_right:       A two-element list or tuple containing the (x,y) coordinate of the top right point of \n",
    "    the viewing window\n",
    "    @param bottom_right:    A two-element linst or tuple containing the (x,y) coordinate of the bottom right point \n",
    "    of the viewing window\n",
    "    \n",
    "    @result viewing_window: List of four 1x4 numpy arrays: left_line, top_line, right_line, bottom_line. Each \n",
    "    numpy array contains four numbers: x1, y1, x2, y2. (x1, y1) is the starting coordinate of the line. (x2, y2) \n",
    "    is the ending coordinate of the line.  \n",
    "    \"\"\"\n",
    "    left_line = np.array([[bottom_left[0],bottom_left[1],top_left[0],top_left[1]]])\n",
    "    top_line = np.array([[top_left[0],top_left[1],top_right[0],top_right[1]]])\n",
    "    right_line = np.array([[top_right[0],top_right[1],bottom_right[0],bottom_right[1]]])\n",
    "    bottom_line = np.array([[bottom_right[0],bottom_right[1],bottom_left[0],bottom_left[1]]])\n",
    "    viewing_window = [left_line,top_line,right_line,bottom_line]\n",
    "\n",
    "    return viewing_window\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh_min=0, thresh_max=255):\n",
    "    \"\"\"\n",
    "    Applies the sobel algorithm to get the absolute derivative of an image with respect to x or y.\n",
    "    \n",
    "    @param img:           input image. MUST be an RGB image. \n",
    "    @orient:              can be 'x' which means take the derivative with respect to x. If it is anything else, it \n",
    "    will take the derivative with respect to y.\n",
    "    @sobel_kernel:        Defines the size of the sobel filter. MUST be an odd number between 3-31. The larger the \n",
    "    kernel size, the more well-defined the gradients. However, computational time will increase as well.\n",
    "    @param thresh_min:    minimum cut-off for gradient threshold. Any pixels below this value will be blacked out.\n",
    "    Default value is zero.\n",
    "    @param thresh_max:    maximum cut-off for gradient threshold. Any pixels above this value will be blacked out.\n",
    "    Default value is 255. \n",
    "    \n",
    "    @result sobel_binary: final resulting image. The resulting image is a binary image.  \n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to gray-scale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Take derivative with respect to x\n",
    "    if (orient == 'x'):\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_32F, 1, 0 ,ksize=sobel_kernel)\n",
    "    # Take derivative with respect to y\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_32F, 0, 1,ksize=sobel_kernel)\n",
    "    \n",
    "    # Take absolute value of derivative    \n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    \n",
    "    # Convert to 8-bit image (0 - 255)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Make copy of scaled_sobel with all zeros\n",
    "    sobel_binary = np.zeros_like(scaled_sobel)\n",
    "    \n",
    "    # Make all pixels within threshold range a value of 1\n",
    "    # Keep all other pixels as 0\n",
    "    sobel_binary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "    \n",
    "    return sobel_binary\n",
    "\n",
    "def sobel_mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    \"\"\"\n",
    "    Uses the sobel algorithm to take the magnitude of the gradient of an image\n",
    "    \n",
    "    @param img:           input image. MUST be an RGB image.\n",
    "    @sobel_kernel:        Defines the size of the sobel filter. MUST be an odd number between 3-31. The larger the \n",
    "    kernel size, the more well-defined the gradients. However, computational time will increase as well. \n",
    "    coordinate of the line. (x2, y2) is the ending coordinate of the line. \n",
    "    @param mag_thresh:    A tuple which contains the minimum and maximum gradient thresholds. (minimum, maximum).\n",
    "    \n",
    "    @result sobel_binary: the resulting image. The resulting image is a binary image. \n",
    "    \"\"\"\n",
    "    thresh_min = mag_thresh[0]\n",
    "    thresh_max = mag_thresh[1]\n",
    "    \n",
    "    # Convert to gray scale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Take derivatives in both x and y direction\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=sobel_kernel)\n",
    "    \n",
    "    # Find magnitude of the gradient\n",
    "    sum_of_squares = np.square(sobelx) + np.square(sobely)\n",
    "    sobel_mag = np.power(sum_of_squares,0.5)\n",
    "    \n",
    "    # Convert to 8-bit image (0 - 255)\n",
    "    scaled_sobel = np.uint8(255*sobel_mag/np.max(sobel_mag))\n",
    "    \n",
    "    # Make a copy of sobel_mag with all zeros\n",
    "    sobel_binary = np.zeros_like(scaled_sobel)\n",
    "    \n",
    "    # Make all pixels within threshold range a value of 1\n",
    "    # Keep all other pixels as 0\n",
    "    sobel_binary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "\n",
    "    return sobel_binary\n",
    "\n",
    "# Function that applies Sobel x and y, \n",
    "# then computes the direction of the gradient\n",
    "# and applies a threshold.\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \"\"\"\n",
    "    Uses the sobel algorithm to find the direction of the gradient of an image\n",
    "\n",
    "    @param img:           input image. MUST be an RGB image. \n",
    "    @param sobel_kernel:  Defines the size of the sobel filter. MUST be an odd number between 3-31. The larger the \n",
    "    kernel size, the more well-defined the gradients. However, computational time will increase as well.\n",
    "    @param thresh:        A tuple which defines the minimum and maximum gradient thresholds. (minimum, maximum)\n",
    "\n",
    "    @result sobel_binary: the resulting image. The resulting image is a binary image.\n",
    "    \"\"\"   \n",
    "    # Min and Max Threshold Angles\n",
    "    thresh_min = thresh[0]\n",
    "    thresh_max = thresh[1]\n",
    "\n",
    "    # Convert to gray scale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    # Calculate the derivatives with respect to x and y\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_32F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_32F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    # Take absolute value of derivatives\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "\n",
    "    # Calculate angle for direction of gradient in radians\n",
    "    sobel_angle = np.arctan2(abs_sobely,abs_sobelx)\n",
    "\n",
    "    # Make a copy of sobel_angle with all zeros\n",
    "    sobel_binary = np.zeros_like(sobel_angle)\n",
    "\n",
    "    # Apply thresholding\n",
    "    sobel_binary[(sobel_angle >= thresh_min) & (sobel_angle <= thresh_max)] = 1\n",
    "\n",
    "    return sobel_binary\n",
    "\n",
    "def region_of_interest(gray, limit_look_ahead):\n",
    "  \"\"\"\n",
    "  Applies a region of interest to a gray-scale image. This function is frequently modified. Currently, it just\n",
    "  blacks out certain rectangular regions. \n",
    "  \n",
    "  @param gray:             Input image. MUST be a gray-scale image\n",
    "  @param limit_look_ahead: A floating point number that must be between 0.0 and 1.0. It determines what percentage\n",
    "  of the top of the image to black out. \n",
    "  \n",
    "  @result copy:            The resulting gray-scale image after the region of interest was applied.\n",
    "  \"\"\"\n",
    "  copy = np.copy(gray) + 1\n",
    "  #copy[:, :225] = 0 \n",
    "  #copy[800:1080, 800:1200] = 0\n",
    "  #copy[0:800, 0:350] = 0\n",
    "  copy[:int(gray.shape[0]*limit_look_ahead), :] = 0\n",
    "  return copy \n",
    "\n",
    "def combined_threshold(image, gradx_low=40, gradx_high=255, mag_low=40, mag_high=255, dir_low=0.7, dir_high=1.3, \\\n",
    "                       s_low=140, s_high=255, l_low=40, l_high=255,  l_agr=205, kernel_size=3):\n",
    "    \"\"\"\n",
    "    @param image:       input image. MUST be RGB.\n",
    "    @param gradx_low:   minimum threshold value for applying gradient with respect to x\n",
    "    @param gradx_high:  maximum threshold value for applying gradient with respect to x\n",
    "    @param mag_low:     minimum threshold value for finding magnitude of the gradient\n",
    "    @param mag_high:    maximum threshold value for finding magnitude of the gradient\n",
    "    @param dir_low:     minimum threshold value for fidning the direction of the gradient\n",
    "    @param dir_high:    maximum threshold value for finding the direction of the gradient\n",
    "    @param s_low:       minimum threshold value for applying color thresholding to S channel from HLS color space\n",
    "    @param s_high:      maximum threshold value for applying color thresholding to S channel from HLS color space\n",
    "    @param l_low:       minimum threshold value for applying color thresholding to L channel from HLS color space\n",
    "    @param l_high:      maximum threshold value for applying color thresholding to L channel from HLS color space\n",
    "    @param l_agr:       minimum threshold value for applying second round of color thresholding to L channel from\n",
    "    HLS color space. Any pixels above this value will be kept. The idea is that very bright pixels during daylight\n",
    "    driving and even during night driving due to street lights and reflectors on the road are most likely lane \n",
    "    line pixels.\n",
    "    @param kernel_size: Defines the size of the sobel filter. MUST be an odd number between 3-31. The larger the \n",
    "    kernel size, the more well-defined the gradients. However, computational time will increase as well.\n",
    "    \n",
    "    @result combined:   The resulting binary image after appling a combination of color and gradient \n",
    "    thresholds\n",
    "    \"\"\"\n",
    "    # Convert image to HLS color space\n",
    "    image_hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    \n",
    "    # Extract S channel\n",
    "    S = image_hls[:,:,2]\n",
    "    \n",
    "    # Apply gradient thresholding to S channel\n",
    "    S_thresholded = np.zeros_like(S)\n",
    "    thresh_S = (s_low, s_high)\n",
    "    S_thresholded[(S >= thresh_S[0]) & (S <= thresh_S[1])] = 1\n",
    "    \n",
    "    # Extract L channel\n",
    "    L = image_hls[:,:,1]\n",
    "    \n",
    "    # Apply gradient thresholding to L channel\n",
    "    L_thresholded = np.zeros_like(L)\n",
    "    thresh_L = (l_low, l_high)\n",
    "    L_thresholded[(L >=thresh_L[0]) & (L <= thresh_L[1])] = 1\n",
    "    \n",
    "    # Apply second round of gradient thresholding using L channel\n",
    "    # If a pixel is extremely bright, above l_agr, keep it. \n",
    "    thresh_L_agr = l_agr\n",
    "    L_thresholded2 = np.zeros_like(L)\n",
    "    L_thresholded2[L>=thresh_L_agr] = 1\n",
    "    \n",
    "    # Apply gradient with respect to x\n",
    "    gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=kernel_size, thresh_min=gradx_low,\n",
    "                             thresh_max=gradx_high)\n",
    "\n",
    "    # Find magnitude of the gradient\n",
    "    mag_binary = sobel_mag_thresh(image, sobel_kernel=kernel_size, mag_thresh=(mag_low,mag_high))\n",
    "    \n",
    "    # Find direction of the gradient\n",
    "    dir_binary = dir_threshold(image,sobel_kernel=kernel_size,thresh=(0.7,1.3))\n",
    "\n",
    "    # Create blank image for combining all the color and gradient thresholds\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    \n",
    "    # Combine all color and gradient thresholds\n",
    "    combined[((mag_binary == 1) & (dir_binary == 1) & (gradx == 1)) | \\\n",
    "             (((S_thresholded == 1) & (L_thresholded == 1)) | (L_thresholded2 == 1))] = 1\n",
    "    \n",
    "    return combined\n",
    "\n",
    "def apply_birdseye(image,source_points,dest_points):\n",
    "    \"\"\"\n",
    "    Applies perspective transformation to input image and obtains a birds-eye view of the image.\n",
    "    \n",
    "    @param image:         input image. The input image should be undistorted.\n",
    "    @param source_points: A 4x2 float32 numpy array where each row defines one of the four points of the source\n",
    "    points used for the perspective transformation. This is the order: \n",
    "    Top left, bottom left, bottom right, top right.\n",
    "    @param dest_points:   A 4x2 float32 numpy array where each row defines one of the four points of the \n",
    "    destination points used for the perspective transformation. \n",
    "    \n",
    "    @result birds_eye_image: the resulting birds-eye view image. \n",
    "    \"\"\"\n",
    "    M = cv2.getPerspectiveTransform(source_points,dest_points)\n",
    "    Minv = cv2.getPerspectiveTransform(dest_points,source_points)\n",
    "    img_size = (image.shape[1],image.shape[0])\n",
    "\n",
    "    birds_eye_image = cv2.warpPerspective(image, M, img_size,\n",
    "                                          flags=cv2.INTER_LINEAR)\n",
    "\n",
    "    return birds_eye_image\n",
    "\n",
    "def process_image(image):\n",
    "    \"\"\"\n",
    "    Takes in an image and performs lane line detection on it. It can only see the two lane lines that define\n",
    "    the car's current lane\n",
    "    \n",
    "    @param: input image. MUST be an RGB image\n",
    "    \n",
    "    @result result: the resulting image with the lane drawn on top.     \n",
    "    \"\"\"\n",
    "    \n",
    "    global previous_warp_zero\n",
    "    clear_flag = 0\n",
    "    \n",
    "    \"\"\"Begin transforming image into a binary birds-eye view with only lane line pixels visible\"\"\"\n",
    "    \n",
    "    # Source points for mobius 1920x1080\n",
    "    src_top_left = [860,460]\n",
    "    src_bottom_left = [500,720]\n",
    "    src_bottom_right = [1375,720]\n",
    "    src_top_right = [950,460]\n",
    "    source_points = np.float32([src_top_left,src_bottom_left,src_bottom_right,\n",
    "                     src_top_right])\n",
    "\n",
    "    # Destination points for mobius 1920x1080\n",
    "    left = 500\n",
    "    right = 1375\n",
    "    bottom = 0\n",
    "    top = 1080\n",
    "    dest_top_left = [left,bottom]\n",
    "    dest_bottom_left = [left,top]\n",
    "    dest_bottom_right = [right,top]\n",
    "    dest_top_right = [right,bottom]\n",
    "    dest_points = np.float32([dest_top_left,dest_bottom_left,dest_bottom_right,\n",
    "                              dest_top_right])\n",
    "\n",
    "    # Get the inverse perspective matrix to be used later to warp predicted lane back onto original image\n",
    "    Minv = cv2.getPerspectiveTransform(dest_points,source_points)\n",
    "    \n",
    "    # Undistort image\n",
    "    image_undistorted = cv2.undistort(image, mtx, dist, None, mtx)\n",
    "    \n",
    "    # Convert to birds-eye view\n",
    "    birdseye_view = apply_birdseye(image_undistorted,source_points,dest_points)\n",
    "    \n",
    "    # Applying Combined Color and Gradient Thresholding to Birds-Eye View Image\n",
    "    combined = combined_threshold(birdseye_view, gradx_low=40, gradx_high=255, mag_low=40, mag_high=255, dir_low=0.7, dir_high=1.3, \\\n",
    "                       s_low=60, s_high=255, l_low=140, l_high=255,  l_agr=205, kernel_size=3)\n",
    "    \n",
    "    #  Use previous frame's lane projection to black out area in between the lane lines\n",
    "    if (previous_warp_zero is not None):\n",
    "        combined[previous_warp_zero == 1] = 0\n",
    "    \n",
    "    # Black out top 40% of image\n",
    "    limit_look_ahead = 0.4\n",
    "    binary_warped = np.logical_and(combined,region_of_interest(combined,limit_look_ahead=limit_look_ahead)).astype(np.uint8)\n",
    "    \n",
    "    \"\"\"Begin the histogram-based window search\"\"\"\n",
    "    \n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # Take a histogram (column-wise) of the bottom portion of the image\n",
    "    \n",
    "    # What faction of the bottom of the image you wish to perform the histogram on (must be between 0.0 and 1.0)\n",
    "    bottom_fraction = 0.15\n",
    "    \n",
    "    # Get the original height of the image\n",
    "    \n",
    "    height = binary_warped.shape[0]\n",
    "    width = binary_warped.shape[1]\n",
    "    \n",
    "    # Perform the histogram on some percentage of the bottom of the image\n",
    "    histogram = np.sum(binary_warped[int(height - height*bottom_fraction):,:], axis=0)\n",
    "\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    windows = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Determines the height of the windows\n",
    "    nwindows = 8\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    lefty_current = image.shape[0] - window_height//2\n",
    "    righty_current = image.shape[0] - window_height//2\n",
    "    \n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 120 # best is 120\n",
    "    \n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 600 # best is 50 (500)\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # Re-center window based on both x and y position\n",
    "    \n",
    "    # Initialize top, bottom, left, and right boundaries of left and right search windows\n",
    "    win_yleft_low = lefty_current + window_height//2\n",
    "    win_yleft_high = lefty_current - window_height//2\n",
    "    win_xleft_low = leftx_current - margin\n",
    "    win_xleft_high = leftx_current + margin\n",
    "    win_yright_low = righty_current + window_height//2\n",
    "    win_yright_high = righty_current - window_height//2\n",
    "    win_xright_low = rightx_current - margin\n",
    "    win_xright_high = rightx_current + margin\n",
    "    \n",
    "    # Initialize the direction the left and right window searches move in\n",
    "    left_dx = 0 # number of pixels to move in the x-direction for left window search\n",
    "    left_dy = -1 # number of pixels to move in the y-direction for left window search\n",
    "    right_dx = 0 # number of pixels to move in the x-direction for right window search\n",
    "    right_dy = -1 # number of pixels to move in the y-direction for right window search\n",
    "    \n",
    "    # margin of wiggle room before stopping window search when it exits the side of the image\n",
    "    side_margin = 1.1 #1.25\n",
    "    # margin of wiggle room before stopping window search when it crosses into other half of image\n",
    "    middle_margin = 5.0 # 1.0\n",
    "    \n",
    "    n_left_windows = 0 # Initialize the number of left windows used\n",
    "    n_right_windows = 0 # Initialize the number of right windows used\n",
    "    min_n_windows = 100 # min number of windows before terminating window search\n",
    "    \n",
    "    \"\"\"\n",
    "    While (the left window search is within the left side of the image (plus some wiggle room) OR minimum number\n",
    "    of left windows have been reached) OR (the right window search is within the right side of the image (plus\n",
    "    some wiggle room) OR minimum number of right windows have been reached)\n",
    "    \"\"\"\n",
    "    while ((((win_xleft_low >= -1*(margin//2)*side_margin) & (win_xleft_high <= (image.shape[1]//2 + ((margin//2)*middle_margin))) & (win_yleft_high > 0)) | (n_left_windows < min_n_windows)) | \\\n",
    "            (((win_xright_low >= (image.shape[1]//2 - ((margin//2)*middle_margin))) & (win_xright_high <= (image.shape[1] + (margin//2)*side_margin)) & (win_yright_high > 0)) | (n_right_windows < min_n_windows))):\n",
    "    \n",
    "        # Do left lane line\n",
    "        # Find left, right, top, bottom, boundaries of window\n",
    "        win_yleft_low = lefty_current + window_height//2\n",
    "        win_yleft_high = lefty_current - window_height//2\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "\n",
    "        # Stop performing left window search if left lane line exits left side of image\n",
    "        if (((win_xleft_low >= -1*(margin//2)*side_margin) & \\\n",
    "             (win_xleft_high <= image.shape[1]//2 + (margin//2)*middle_margin)) | \\\n",
    "             (n_left_windows < min_n_windows)): # 1.5\n",
    "            n_left_windows += 1\n",
    "            # Draw window\n",
    "            cv2.rectangle(windows,(win_xleft_low,win_yleft_low),(win_xleft_high,win_yleft_high),\n",
    "            (0,255,0), 2) \n",
    "            # Get indicies of nonzero pixels within window\n",
    "            good_left_inds = ((nonzeroy < win_yleft_low) & (nonzeroy >= win_yleft_high) & \n",
    "            (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            # Append these indicies to list of left lane line indicies\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            # If you found > minpix pixels, recenter next window on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                # Always re-center x position; let new x position go to the left or right\n",
    "                leftx_previous = leftx_current\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "                left_dx = leftx_current - leftx_previous\n",
    "                # Only re-center y position if the new center is higher up on the image than the previous center\n",
    "                # higher up on the image means a smaller y value\n",
    "                # 0 y value is at the top of the image\n",
    "                if (np.int(np.mean(nonzeroy[good_left_inds])) < lefty_current):\n",
    "                    lefty_previous = lefty_current \n",
    "                    lefty_current = np.int(np.mean(nonzeroy[good_left_inds]))\n",
    "                    left_dy = lefty_current - lefty_previous\n",
    "                # if re-centering causes y to go down (higher y value), do not let window search to go back down\n",
    "                # keep window search moving in previous y direction\n",
    "                else:\n",
    "                    lefty_current += left_dy\n",
    "            # if mininum number of pixels was not found, keep moving in previous x and y direction\n",
    "            else:\n",
    "                leftx_current += left_dx\n",
    "                lefty_current += left_dy\n",
    "            \n",
    "        \n",
    "        # Do right lane line\n",
    "        # Find left and right boundaries of window\n",
    "        win_yright_low = righty_current + window_height//2\n",
    "        win_yright_high = righty_current - window_height//2\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "\n",
    "        # Stop performing right window search if right lane line exits right side of image\n",
    "        if (((win_xright_high <= image.shape[1] + (margin//2)*side_margin) & \\\n",
    "             (win_xright_low >=(image.shape[1]//2 - (margin//2)*middle_margin)) | \\\n",
    "             (n_right_windows < min_n_windows))): # 1.5\n",
    "            n_right_windows += 1\n",
    "            # Draw Window\n",
    "            cv2.rectangle(windows,(win_xright_low,win_yright_low),(win_xright_high,win_yright_high),\n",
    "            (0,255,0), 2) \n",
    "            # Get indicies of nonzero pixels within window\n",
    "            good_right_inds = ((nonzeroy < win_yright_low) & (nonzeroy >= win_yright_high) & \n",
    "            (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "            # Append these indicies to list of right lane line indicies\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "            # if you found > minpix pixels, recenter next window on mean x-position\n",
    "            if len(good_right_inds) > minpix: \n",
    "                rightx_previous = rightx_current\n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "                right_dx = rightx_current - rightx_previous\n",
    "                # only re-center y position if the new y-position is higher up (lower y value)\n",
    "                if (np.int(np.mean(nonzeroy[good_right_inds])) < righty_current):\n",
    "                    righty_previous = righty_current\n",
    "                    righty_current = np.int(np.mean(nonzeroy[good_right_inds]))\n",
    "                    right_dy = righty_current - righty_previous\n",
    "                # if re-centering causes y to go down (higher y value), do not let window search to go back down\n",
    "                # keep window search moving in previous y direction\n",
    "                else:\n",
    "                    righty_current += right_dy\n",
    "            # if mininum number of pixels was not found, keep moving in previous x and y direction\n",
    "            else:\n",
    "                rightx_current += right_dx\n",
    "                righty_current += right_dy\n",
    "\n",
    "    \"\"\"Begin finding best-fit line for both lane lines\"\"\"\n",
    "    \n",
    "    # Concatenate the arrays of indices\n",
    "    if (len(left_lane_inds) > 0):\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    if (len(right_lane_inds) > 0):\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    left_lane_inds = np.unique(left_lane_inds) # get rid of repeats\n",
    "    right_lane_inds = np.unique(right_lane_inds) # get rid of repeats\n",
    "    \n",
    "    # Temporary fix to account for rare case when no lane line pixels were found\n",
    "    if (len(left_lane_inds) > 0):\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "    else:\n",
    "        leftx = []\n",
    "        lefty = []\n",
    "    if (len(right_lane_inds) > 0):\n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds] \n",
    "    else:\n",
    "        rightx = []\n",
    "        righty = []\n",
    "      \n",
    "    # Factor by which to shift starting y position of best-fit line for the lane lines\n",
    "    # 1.0 means left-lane line starts at the bottom of the image; \n",
    "    shift_lane_up = 1.0 # originally 1.25\n",
    "    # y values for plotting the best-fit lines\n",
    "    ploty = np.linspace(limit_look_ahead*image.shape[0], (binary_warped.shape[0]-1)*shift_lane_up, binary_warped.shape[0] )\n",
    "    \n",
    "    # initial \n",
    "    left_fit = [0,0,0]\n",
    "    right_fit = [0,0, image.shape[1]]\n",
    "    n = 2 # degree of polynomial for best-fit line (2 works best)\n",
    "    \n",
    "    # Fit a second-order polynomial for left lane line\n",
    "    if ((len(lefty) > 50) & (len(leftx) > 50)):\n",
    "        # Use RANSAC algorithm to find best-fit line for left lane line\n",
    "        left_model = make_pipeline(PolynomialFeatures(n), RANSACRegressor(random_state=42))\n",
    "        left_model.fit(lefty.reshape(-1,1), leftx)\n",
    "\n",
    "        \"\"\"\n",
    "        For some reason, the one line of code below fails to return the correct coefficients of the best-fit \n",
    "        line. It only returns 2/3 of the coefficients. One coefficient is always zero...So the coefficients\n",
    "        have to be re-calculated using np.polyfit. We need the coefficients to calculate radius of curvature\n",
    "        #left_fit = left_model.named_steps['ransacregressor'].estimator_.coef_\n",
    "        \"\"\"\n",
    "        \n",
    "        left_fitx = left_model.predict(ploty.reshape(-1,1))\n",
    "        left_fit = np.polyfit(ploty,left_fitx,2)\n",
    "              \n",
    "    else:\n",
    "        left_fit = [0,0,0]\n",
    "        clear_flag = 1\n",
    "     \n",
    "    # Fit a second-order polynomial for right lane line\n",
    "    if ((len(righty) > 50) & (len(rightx) > 50)):\n",
    "        \n",
    "        right_model = make_pipeline(PolynomialFeatures(n), RANSACRegressor(random_state=42))\n",
    "        right_model.fit(righty.reshape(-1,1), rightx)\n",
    "        \n",
    "        \"\"\"\n",
    "        For some reason, the one line of code below fails to return the correct coefficients of the best-fit \n",
    "        line. It only returns 2/3 of the coefficients. One coefficient is always zero...So the coefficients\n",
    "        have to be re-calculated using np.polyfit. We need the coefficients to calculate radius of curvature\n",
    "        #right_fit = right_model.named_steps['ransacregressor'].estimator_.coef_\n",
    "        \"\"\"\n",
    "        \n",
    "        right_fitx = right_model.predict(ploty.reshape(-1,1))\n",
    "        right_fit = np.polyfit(ploty,right_fitx,2)\n",
    "                \n",
    "    else:\n",
    "        clear_flag = 1\n",
    "        right_fit = [0,image.shape[1]]\n",
    "\n",
    "    \"\"\"Visualize results and calculate radii of curvature and ceter offset\"\"\"\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    # Temporary fix for rare case when no lane line pixels were found\n",
    "    if (len(left_lane_inds) > 0):\n",
    "        windows[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    if (len(right_lane_inds) > 0):\n",
    "        windows[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    # Create an image to draw on the best-fit line\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Create an image that will have the best-fit lines colored in and then overlay it on top of out_img\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    \n",
    "    # Color in left and right line pixels on out_img\n",
    "    # Temporary fix for rare case when non lane line pixels were found\n",
    "    if (len(left_lane_inds) > 0):\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    if (len(right_lane_inds) > 0):\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                                  ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                                  ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "\n",
    "    # Draw the best-fit lines and overlay onto out_img\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    best_fit = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    # For visualizing the region of interest to be blakced out in between the lane lines\n",
    "    best_fit[previous_warp_zero == 1] = (255,255,0)\n",
    "\n",
    "    # Calculating radius of curvature at bottom of picture in pixels\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = ((1 + (2*left_fit[0]*y_eval + left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "    right_curverad = ((1 + (2*right_fit[0]*y_eval + right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    yinches_per_pix = 8/480\n",
    "    xinches_per_pix = 5/640\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    if (((len(lefty) != 0) & (len(leftx) != 0))):\n",
    "        left_fit_cr = np.polyfit(lefty*yinches_per_pix, leftx*xinches_per_pix, 2)\n",
    "    else:\n",
    "        left_fit_cr = [0,0,0]\n",
    "    if (((len(righty) != 0) & (len(rightx) != 0))):\n",
    "        right_fit_cr = np.polyfit(righty*yinches_per_pix, rightx*xinches_per_pix, 2)\n",
    "    else:\n",
    "        right_fit_cr = [0,0,1920*xinches_per_pix]\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*yinches_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*yinches_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "    # Example values: 632.1 m    626.2 m\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    #warp_zero = np.zeros((int(height*1.25),width),np.uint8)\n",
    "    \n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \"\"\"\n",
    "    previous_warp_zero = warp_zero\n",
    "    pts_left_roi = np.array([np.transpose(np.vstack([left_fitx*1.05, ploty]))])\n",
    "    pts_right_roi = np.array([np.flipud(np.transpose(np.vstack([right_fitx*0.95, ploty])))])\n",
    "    pts_roi = np.hstack((pts_left_roi, pts_right_roi))\n",
    "    if (clear_flag == 0):\n",
    "        cv2.fillPoly(warp_zero, np.int_([pts_roi]), 1)\n",
    "    else:\n",
    "        cv2.fillPoly(warp_zero, np.int_([pts_roi]), 0)\n",
    "    \"\"\"\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(image, 1, newwarp, 0.3, 0)\n",
    "\n",
    "    vehicle_center = width/2\n",
    "    left_lane_position = (left_fit[0] * (height**2)) + (left_fit[1] * height) + left_fit[2]\n",
    "    right_lane_position = (right_fit[0] * (height**2)) + (right_fit[1] * height) + right_fit[2]\n",
    "    actual_center = left_lane_position + (right_lane_position - left_lane_position) / 2\n",
    "    vehicle_position = (actual_center - vehicle_center) * xinches_per_pix\n",
    "    vehicle_position = round((vehicle_position),2)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    #cv2.putText(result, \"Left Radius Of Curvature: \" + str(round(left_curverad,0)), (50, 50), font, 1.1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    #cv2.putText(result, \"Right Radius Of Curvature: \" + str(round(right_curverad,0)), (50, 100), font, 1.1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    if (vehicle_position < 0):\n",
    "        vehicle_position_str = str(np.absolute(vehicle_position)) + \" inches right of center\"\n",
    "    elif (vehicle_position > 0):\n",
    "        vehicle_position_str = str(np.absolute(vehicle_position)) + \" inches left of center\"\n",
    "    else:\n",
    "        vehicle_position_str =  \"on center\"\n",
    "    #cv2.putText(result, vehicle_position_str, (50,150), font, 1.1, (255,255,255), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Draw the following four images on top to help visualize and debug algorithm\n",
    "    birdseye_view = resize(birdseye_view, (height//4,width//4))*255\n",
    "    binary_warped = resize(binary_warped, (height//4,width//4))*255\n",
    "    windows = resize(windows, (height//4,width//4))*255\n",
    "    best_fit = resize(best_fit, (height//4,width//4))*255\n",
    "    \n",
    "    binary_warped_color = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "\n",
    "    offset = [0, int(image.shape[1]*0.25), int(image.shape[1]*0.5), int(image.shape[1]*0.75)]\n",
    "    width, height = image.shape[1]//4, image.shape[0]//4\n",
    "    \n",
    "    result[:height, offset[0]: offset[0] + width] = birdseye_view\n",
    "    result[:height, offset[1]: offset[1] + width] = binary_warped_color\n",
    "    result[:height, offset[2]: offset[2] + width] = windows\n",
    "    result[:height, offset[3]: offset[3] + width] = best_fit\n",
    "\n",
    "    return result\n",
    "print('done')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video Real_Car_Images_And_Videos/Bay_Area_Output_Videos/output.mp4\n",
      "[MoviePy] Writing video Real_Car_Images_And_Videos/Bay_Area_Output_Videos/output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/451 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/451 [00:00<06:48,  1.10it/s]\u001b[A\n",
      "  0%|          | 2/451 [00:01<06:46,  1.11it/s]\u001b[A\n",
      "  1%|          | 3/451 [00:02<06:45,  1.11it/s]\u001b[A\n",
      "  1%|          | 4/451 [00:03<06:41,  1.11it/s]\u001b[A\n",
      "  1%|          | 5/451 [00:04<06:39,  1.12it/s]\u001b[A\n",
      "  1%|▏         | 6/451 [00:05<06:38,  1.12it/s]\u001b[A\n",
      "  2%|▏         | 7/451 [00:06<06:37,  1.12it/s]\u001b[A\n",
      "  2%|▏         | 8/451 [00:07<06:34,  1.12it/s]\u001b[A\n",
      "  2%|▏         | 9/451 [00:08<06:32,  1.12it/s]\u001b[A\n",
      "  2%|▏         | 10/451 [00:08<06:31,  1.13it/s]\u001b[A\n",
      "  2%|▏         | 11/451 [00:09<06:30,  1.13it/s]\u001b[A\n",
      "  3%|▎         | 12/451 [00:10<06:30,  1.13it/s]\u001b[A\n",
      "  3%|▎         | 13/451 [00:11<06:29,  1.12it/s]\u001b[A\n",
      "  3%|▎         | 14/451 [00:12<06:29,  1.12it/s]\u001b[A\n",
      "  3%|▎         | 15/451 [00:13<06:29,  1.12it/s]\u001b[A\n",
      "  4%|▎         | 16/451 [00:14<06:32,  1.11it/s]\u001b[A\n",
      "  4%|▍         | 17/451 [00:15<06:35,  1.10it/s]\u001b[A\n",
      "  4%|▍         | 18/451 [00:16<06:40,  1.08it/s]\u001b[A\n",
      "  4%|▍         | 19/451 [00:17<06:43,  1.07it/s]\u001b[A\n",
      "  4%|▍         | 20/451 [00:18<06:48,  1.06it/s]\u001b[A\n",
      "  5%|▍         | 21/451 [00:20<06:50,  1.05it/s]\u001b[A\n",
      "  5%|▍         | 22/451 [00:20<06:48,  1.05it/s]\u001b[A\n",
      "  5%|▌         | 23/451 [00:22<06:50,  1.04it/s]\u001b[A\n",
      "  5%|▌         | 24/451 [00:23<06:52,  1.04it/s]\u001b[A\n",
      "  6%|▌         | 25/451 [00:24<06:55,  1.02it/s]\u001b[A\n",
      "  6%|▌         | 26/451 [00:25<06:54,  1.02it/s]\u001b[A\n",
      "  6%|▌         | 27/451 [00:26<06:55,  1.02it/s]\u001b[A\n",
      "  6%|▌         | 28/451 [00:27<06:55,  1.02it/s]\u001b[A\n",
      "  6%|▋         | 29/451 [00:28<06:57,  1.01it/s]\u001b[A\n",
      "  7%|▋         | 30/451 [00:30<07:02,  1.00s/it]\u001b[A\n",
      "  7%|▋         | 31/451 [00:31<07:07,  1.02s/it]\u001b[A\n",
      "  7%|▋         | 32/451 [00:33<07:12,  1.03s/it]\u001b[A\n",
      "  7%|▋         | 33/451 [00:34<07:20,  1.05s/it]\u001b[A\n",
      "  8%|▊         | 34/451 [00:36<07:22,  1.06s/it]\u001b[A\n",
      "  8%|▊         | 35/451 [00:37<07:24,  1.07s/it]\u001b[A\n",
      "  8%|▊         | 36/451 [00:38<07:22,  1.07s/it]\u001b[A\n",
      "  8%|▊         | 37/451 [00:39<07:21,  1.07s/it]\u001b[A\n",
      "  8%|▊         | 38/451 [00:40<07:19,  1.07s/it]\u001b[A\n",
      "  9%|▊         | 39/451 [00:41<07:17,  1.06s/it]\u001b[A\n",
      "  9%|▉         | 40/451 [00:42<07:15,  1.06s/it]\u001b[A\n",
      "  9%|▉         | 41/451 [00:43<07:13,  1.06s/it]\u001b[A\n",
      "  9%|▉         | 42/451 [00:44<07:11,  1.05s/it]\u001b[A\n",
      " 10%|▉         | 43/451 [00:45<07:10,  1.06s/it]\u001b[A\n",
      " 10%|▉         | 44/451 [00:46<07:08,  1.05s/it]\u001b[A\n",
      " 10%|▉         | 45/451 [00:47<07:06,  1.05s/it]\u001b[A\n",
      " 10%|█         | 46/451 [00:48<07:04,  1.05s/it]\u001b[A\n",
      " 10%|█         | 47/451 [00:49<07:03,  1.05s/it]\u001b[A\n",
      " 11%|█         | 48/451 [00:50<07:01,  1.05s/it]\u001b[A\n",
      " 11%|█         | 49/451 [00:51<06:59,  1.04s/it]\u001b[A\n",
      " 11%|█         | 50/451 [00:52<06:58,  1.04s/it]\u001b[A\n",
      " 11%|█▏        | 51/451 [00:53<06:56,  1.04s/it]\u001b[A\n",
      " 12%|█▏        | 52/451 [00:54<06:55,  1.04s/it]\u001b[A\n",
      " 12%|█▏        | 53/451 [00:55<06:54,  1.04s/it]\u001b[A\n",
      " 12%|█▏        | 54/451 [00:56<06:52,  1.04s/it]\u001b[A\n",
      " 12%|█▏        | 55/451 [00:57<06:51,  1.04s/it]\u001b[A\n",
      " 12%|█▏        | 56/451 [00:58<06:49,  1.04s/it]\u001b[A\n",
      " 13%|█▎        | 57/451 [00:59<06:48,  1.04s/it]\u001b[A\n",
      " 13%|█▎        | 58/451 [01:00<06:46,  1.04s/it]\u001b[A\n",
      " 13%|█▎        | 59/451 [01:01<06:45,  1.03s/it]\u001b[A\n",
      " 13%|█▎        | 60/451 [01:01<06:43,  1.03s/it]\u001b[A\n",
      " 14%|█▎        | 61/451 [01:02<06:42,  1.03s/it]\u001b[A\n",
      " 14%|█▎        | 62/451 [01:03<06:41,  1.03s/it]\u001b[A\n",
      " 14%|█▍        | 63/451 [01:04<06:39,  1.03s/it]\u001b[A\n",
      " 14%|█▍        | 64/451 [01:05<06:38,  1.03s/it]\u001b[A\n",
      " 14%|█▍        | 65/451 [01:06<06:36,  1.03s/it]\u001b[A\n",
      " 15%|█▍        | 66/451 [01:07<06:34,  1.03s/it]\u001b[A\n",
      " 15%|█▍        | 67/451 [01:08<06:33,  1.03s/it]\u001b[A\n",
      " 15%|█▌        | 68/451 [01:09<06:32,  1.02s/it]\u001b[A\n",
      " 15%|█▌        | 69/451 [01:10<06:30,  1.02s/it]\u001b[A\n",
      " 16%|█▌        | 70/451 [01:11<06:29,  1.02s/it]\u001b[A\n",
      " 16%|█▌        | 71/451 [01:12<06:27,  1.02s/it]\u001b[A\n",
      " 16%|█▌        | 72/451 [01:13<06:25,  1.02s/it]\u001b[A\n",
      " 16%|█▌        | 73/451 [01:14<06:24,  1.02s/it]\u001b[A\n",
      " 16%|█▋        | 74/451 [01:15<06:22,  1.01s/it]\u001b[A\n",
      " 17%|█▋        | 75/451 [01:15<06:20,  1.01s/it]\u001b[A\n",
      " 17%|█▋        | 76/451 [01:16<06:19,  1.01s/it]\u001b[A\n",
      " 17%|█▋        | 77/451 [01:17<06:17,  1.01s/it]\u001b[A\n",
      " 17%|█▋        | 78/451 [01:18<06:16,  1.01s/it]\u001b[A\n",
      " 18%|█▊        | 79/451 [01:19<06:14,  1.01s/it]\u001b[A\n",
      " 18%|█▊        | 80/451 [01:20<06:13,  1.01s/it]\u001b[A\n",
      " 18%|█▊        | 81/451 [01:21<06:11,  1.00s/it]\u001b[A\n",
      " 18%|█▊        | 82/451 [01:22<06:10,  1.00s/it]\u001b[A\n",
      " 18%|█▊        | 83/451 [01:23<06:09,  1.00s/it]\u001b[A\n",
      " 19%|█▊        | 84/451 [01:24<06:07,  1.00s/it]\u001b[A\n",
      " 19%|█▉        | 85/451 [01:25<06:06,  1.00s/it]\u001b[A\n",
      " 19%|█▉        | 86/451 [01:26<06:05,  1.00s/it]\u001b[A\n",
      " 19%|█▉        | 87/451 [01:26<06:03,  1.00it/s]\u001b[A\n",
      " 20%|█▉        | 88/451 [01:27<06:02,  1.00it/s]\u001b[A\n",
      " 20%|█▉        | 89/451 [01:28<06:01,  1.00it/s]\u001b[A\n",
      " 20%|█▉        | 90/451 [01:29<05:59,  1.00it/s]\u001b[A\n",
      " 20%|██        | 91/451 [01:30<05:58,  1.00it/s]\u001b[A\n",
      " 20%|██        | 92/451 [01:31<05:57,  1.01it/s]\u001b[A\n",
      " 21%|██        | 93/451 [01:32<05:55,  1.01it/s]\u001b[A\n",
      " 21%|██        | 94/451 [01:33<05:54,  1.01it/s]\u001b[A\n",
      " 21%|██        | 95/451 [01:34<05:53,  1.01it/s]\u001b[A\n",
      " 21%|██▏       | 96/451 [01:35<05:51,  1.01it/s]\u001b[A\n",
      " 22%|██▏       | 97/451 [01:36<05:50,  1.01it/s]\u001b[A\n",
      " 22%|██▏       | 98/451 [01:36<05:49,  1.01it/s]\u001b[A\n",
      " 22%|██▏       | 99/451 [01:37<05:47,  1.01it/s]\u001b[A\n",
      " 22%|██▏       | 100/451 [01:38<05:46,  1.01it/s]\u001b[A\n",
      " 22%|██▏       | 101/451 [01:39<05:45,  1.01it/s]\u001b[A\n",
      " 23%|██▎       | 102/451 [01:40<05:43,  1.01it/s]\u001b[A\n",
      " 23%|██▎       | 103/451 [01:41<05:42,  1.02it/s]\u001b[A\n",
      " 23%|██▎       | 104/451 [01:42<05:41,  1.02it/s]\u001b[A\n",
      " 23%|██▎       | 105/451 [01:43<05:40,  1.02it/s]\u001b[A\n",
      " 24%|██▎       | 106/451 [01:44<05:38,  1.02it/s]\u001b[A\n",
      " 24%|██▎       | 107/451 [01:45<05:37,  1.02it/s]\u001b[A\n",
      " 24%|██▍       | 108/451 [01:45<05:36,  1.02it/s]\u001b[A\n",
      " 24%|██▍       | 109/451 [01:46<05:35,  1.02it/s]\u001b[A\n",
      " 24%|██▍       | 110/451 [01:47<05:33,  1.02it/s]\u001b[A\n",
      " 25%|██▍       | 111/451 [01:48<05:32,  1.02it/s]\u001b[A\n",
      " 25%|██▍       | 112/451 [01:49<05:31,  1.02it/s]\u001b[A\n",
      " 25%|██▌       | 113/451 [01:50<05:30,  1.02it/s]\u001b[A\n",
      " 25%|██▌       | 114/451 [01:51<05:29,  1.02it/s]\u001b[A\n",
      " 25%|██▌       | 115/451 [01:52<05:28,  1.02it/s]\u001b[A\n",
      " 26%|██▌       | 116/451 [01:53<05:26,  1.02it/s]\u001b[A\n",
      " 26%|██▌       | 117/451 [01:54<05:25,  1.03it/s]\u001b[A\n",
      " 26%|██▌       | 118/451 [01:55<05:24,  1.03it/s]\u001b[A\n",
      " 26%|██▋       | 119/451 [01:55<05:23,  1.03it/s]\u001b[A\n",
      " 27%|██▋       | 120/451 [01:56<05:22,  1.03it/s]\u001b[A\n",
      " 27%|██▋       | 121/451 [01:57<05:20,  1.03it/s]\u001b[A\n",
      " 27%|██▋       | 122/451 [01:58<05:19,  1.03it/s]\u001b[A\n",
      " 27%|██▋       | 123/451 [01:59<05:18,  1.03it/s]\u001b[A\n",
      " 27%|██▋       | 124/451 [02:00<05:17,  1.03it/s]\u001b[A\n",
      " 28%|██▊       | 125/451 [02:01<05:16,  1.03it/s]\u001b[A\n",
      " 28%|██▊       | 126/451 [02:02<05:15,  1.03it/s]\u001b[A\n",
      " 28%|██▊       | 127/451 [02:03<05:14,  1.03it/s]\u001b[A\n",
      " 28%|██▊       | 128/451 [02:04<05:13,  1.03it/s]\u001b[A\n",
      " 29%|██▊       | 129/451 [02:04<05:11,  1.03it/s]\u001b[A\n",
      " 29%|██▉       | 130/451 [02:05<05:10,  1.03it/s]\u001b[A\n",
      " 29%|██▉       | 131/451 [02:06<05:09,  1.03it/s]\u001b[A\n",
      " 29%|██▉       | 132/451 [02:07<05:08,  1.04it/s]\u001b[A\n",
      " 29%|██▉       | 133/451 [02:08<05:06,  1.04it/s]\u001b[A\n",
      " 30%|██▉       | 134/451 [02:09<05:05,  1.04it/s]\u001b[A\n",
      " 30%|██▉       | 135/451 [02:10<05:04,  1.04it/s]\u001b[A\n",
      " 30%|███       | 136/451 [02:10<05:03,  1.04it/s]\u001b[A\n",
      " 30%|███       | 137/451 [02:11<05:02,  1.04it/s]\u001b[A\n",
      " 31%|███       | 138/451 [02:12<05:01,  1.04it/s]\u001b[A\n",
      " 31%|███       | 139/451 [02:13<04:59,  1.04it/s]\u001b[A\n",
      " 31%|███       | 140/451 [02:14<04:58,  1.04it/s]\u001b[A\n",
      " 31%|███▏      | 141/451 [02:15<04:57,  1.04it/s]\u001b[A\n",
      " 31%|███▏      | 142/451 [02:16<04:56,  1.04it/s]\u001b[A\n",
      " 32%|███▏      | 143/451 [02:16<04:55,  1.04it/s]\u001b[A\n",
      " 32%|███▏      | 144/451 [02:17<04:53,  1.04it/s]\u001b[A\n",
      " 32%|███▏      | 145/451 [02:18<04:52,  1.05it/s]\u001b[A\n",
      " 32%|███▏      | 146/451 [02:19<04:51,  1.05it/s]\u001b[A\n",
      " 33%|███▎      | 147/451 [02:20<04:50,  1.05it/s]\u001b[A\n",
      " 33%|███▎      | 148/451 [02:21<04:49,  1.05it/s]\u001b[A\n",
      " 33%|███▎      | 149/451 [02:22<04:47,  1.05it/s]\u001b[A\n",
      " 33%|███▎      | 150/451 [02:22<04:46,  1.05it/s]\u001b[A\n",
      " 33%|███▎      | 151/451 [02:23<04:45,  1.05it/s]\u001b[A\n",
      " 34%|███▎      | 152/451 [02:24<04:44,  1.05it/s]\u001b[A\n",
      " 34%|███▍      | 153/451 [02:25<04:43,  1.05it/s]\u001b[A\n",
      " 34%|███▍      | 154/451 [02:26<04:42,  1.05it/s]\u001b[A\n",
      " 34%|███▍      | 155/451 [02:27<04:40,  1.05it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 156/451 [02:27<04:39,  1.05it/s]\u001b[A\n",
      " 35%|███▍      | 157/451 [02:28<04:38,  1.05it/s]\u001b[A\n",
      " 35%|███▌      | 158/451 [02:29<04:37,  1.06it/s]\u001b[A\n",
      " 35%|███▌      | 159/451 [02:30<04:36,  1.06it/s]\u001b[A\n",
      " 35%|███▌      | 160/451 [02:31<04:35,  1.06it/s]\u001b[A\n",
      " 36%|███▌      | 161/451 [02:32<04:34,  1.06it/s]\u001b[A\n",
      " 36%|███▌      | 162/451 [02:33<04:33,  1.06it/s]\u001b[A\n",
      " 36%|███▌      | 163/451 [02:34<04:32,  1.06it/s]\u001b[A\n",
      " 36%|███▋      | 164/451 [02:35<04:32,  1.05it/s]\u001b[A\n",
      " 37%|███▋      | 165/451 [02:37<04:32,  1.05it/s]\u001b[A\n",
      " 37%|███▋      | 166/451 [02:38<04:31,  1.05it/s]\u001b[A\n",
      " 37%|███▋      | 167/451 [02:39<04:30,  1.05it/s]\u001b[A\n",
      " 37%|███▋      | 168/451 [02:39<04:29,  1.05it/s]\u001b[A\n",
      " 37%|███▋      | 169/451 [02:40<04:28,  1.05it/s]\u001b[A\n",
      " 38%|███▊      | 170/451 [02:41<04:27,  1.05it/s]\u001b[A\n",
      " 38%|███▊      | 171/451 [02:42<04:25,  1.05it/s]\u001b[A\n",
      " 38%|███▊      | 172/451 [02:43<04:24,  1.05it/s]\u001b[A\n",
      " 38%|███▊      | 173/451 [02:44<04:23,  1.05it/s]\u001b[A\n",
      " 39%|███▊      | 174/451 [02:44<04:22,  1.05it/s]\u001b[A\n",
      " 39%|███▉      | 175/451 [02:45<04:21,  1.06it/s]\u001b[A\n",
      " 39%|███▉      | 176/451 [02:46<04:20,  1.06it/s]\u001b[A\n",
      " 39%|███▉      | 177/451 [02:47<04:19,  1.06it/s]\u001b[A\n",
      " 39%|███▉      | 178/451 [02:48<04:18,  1.06it/s]\u001b[A\n",
      " 40%|███▉      | 179/451 [02:49<04:17,  1.06it/s]\u001b[A\n",
      " 40%|███▉      | 180/451 [02:50<04:15,  1.06it/s]\u001b[A\n",
      " 40%|████      | 181/451 [02:50<04:14,  1.06it/s]\u001b[A\n",
      " 40%|████      | 182/451 [02:51<04:13,  1.06it/s]\u001b[A\n",
      " 41%|████      | 183/451 [02:52<04:12,  1.06it/s]\u001b[A\n",
      " 41%|████      | 184/451 [02:53<04:11,  1.06it/s]\u001b[A\n",
      " 41%|████      | 185/451 [02:54<04:10,  1.06it/s]\u001b[A\n",
      " 41%|████      | 186/451 [02:55<04:09,  1.06it/s]\u001b[A\n",
      " 41%|████▏     | 187/451 [02:56<04:08,  1.06it/s]\u001b[A\n",
      " 42%|████▏     | 188/451 [02:56<04:07,  1.06it/s]\u001b[A\n",
      " 42%|████▏     | 189/451 [02:57<04:06,  1.06it/s]\u001b[A\n",
      " 42%|████▏     | 190/451 [02:58<04:05,  1.06it/s]\u001b[A\n",
      " 42%|████▏     | 191/451 [03:00<04:05,  1.06it/s]\u001b[A\n",
      " 43%|████▎     | 192/451 [03:01<04:04,  1.06it/s]\u001b[A\n",
      " 43%|████▎     | 193/451 [03:01<04:03,  1.06it/s]\u001b[A\n",
      " 43%|████▎     | 194/451 [03:02<04:02,  1.06it/s]\u001b[A\n",
      " 43%|████▎     | 195/451 [03:03<04:01,  1.06it/s]\u001b[A\n",
      " 43%|████▎     | 196/451 [03:04<03:59,  1.06it/s]\u001b[A\n",
      " 44%|████▎     | 197/451 [03:05<03:58,  1.06it/s]\u001b[A\n",
      " 44%|████▍     | 198/451 [03:06<03:57,  1.06it/s]\u001b[A\n",
      " 44%|████▍     | 199/451 [03:06<03:56,  1.06it/s]\u001b[A\n",
      " 44%|████▍     | 200/451 [03:07<03:55,  1.06it/s]\u001b[A\n",
      " 45%|████▍     | 201/451 [03:08<03:54,  1.07it/s]\u001b[A\n",
      " 45%|████▍     | 202/451 [03:09<03:53,  1.07it/s]\u001b[A\n",
      " 45%|████▌     | 203/451 [03:10<03:52,  1.07it/s]\u001b[A\n",
      " 45%|████▌     | 204/451 [03:11<03:51,  1.07it/s]\u001b[A\n",
      " 45%|████▌     | 205/451 [03:12<03:50,  1.07it/s]\u001b[A\n",
      " 46%|████▌     | 206/451 [03:13<03:49,  1.07it/s]\u001b[A\n",
      " 46%|████▌     | 207/451 [03:13<03:48,  1.07it/s]\u001b[A\n",
      " 46%|████▌     | 208/451 [03:14<03:47,  1.07it/s]\u001b[A\n",
      " 46%|████▋     | 209/451 [03:15<03:46,  1.07it/s]\u001b[A\n",
      " 47%|████▋     | 210/451 [03:16<03:45,  1.07it/s]\u001b[A\n",
      " 47%|████▋     | 211/451 [03:17<03:44,  1.07it/s]\u001b[A\n",
      " 47%|████▋     | 212/451 [03:18<03:43,  1.07it/s]\u001b[A\n",
      " 47%|████▋     | 213/451 [03:19<03:42,  1.07it/s]\u001b[A\n",
      " 47%|████▋     | 214/451 [03:19<03:41,  1.07it/s]\u001b[A\n",
      " 48%|████▊     | 215/451 [03:20<03:40,  1.07it/s]\u001b[A\n",
      " 48%|████▊     | 216/451 [03:21<03:39,  1.07it/s]\u001b[A\n",
      " 48%|████▊     | 217/451 [03:22<03:38,  1.07it/s]\u001b[A\n",
      " 48%|████▊     | 218/451 [03:23<03:37,  1.07it/s]\u001b[A\n",
      " 49%|████▊     | 219/451 [03:24<03:36,  1.07it/s]\u001b[A\n",
      " 49%|████▉     | 220/451 [03:24<03:35,  1.07it/s]\u001b[A\n",
      " 49%|████▉     | 221/451 [03:25<03:34,  1.07it/s]\u001b[A\n",
      " 49%|████▉     | 222/451 [03:26<03:33,  1.07it/s]\u001b[A\n",
      " 49%|████▉     | 223/451 [03:27<03:32,  1.07it/s]\u001b[A\n",
      " 50%|████▉     | 224/451 [03:28<03:31,  1.08it/s]\u001b[A\n",
      " 50%|████▉     | 225/451 [03:29<03:30,  1.08it/s]\u001b[A\n",
      " 50%|█████     | 226/451 [03:30<03:29,  1.08it/s]\u001b[A\n",
      " 50%|█████     | 227/451 [03:30<03:28,  1.08it/s]\u001b[A\n",
      " 51%|█████     | 228/451 [03:31<03:27,  1.08it/s]\u001b[A\n",
      " 51%|█████     | 229/451 [03:32<03:26,  1.08it/s]\u001b[A\n",
      " 51%|█████     | 230/451 [03:33<03:25,  1.08it/s]\u001b[A\n",
      " 51%|█████     | 231/451 [03:34<03:24,  1.08it/s]\u001b[A\n",
      " 51%|█████▏    | 232/451 [03:35<03:23,  1.08it/s]\u001b[A\n",
      " 52%|█████▏    | 233/451 [03:36<03:22,  1.08it/s]\u001b[A\n",
      " 52%|█████▏    | 234/451 [03:36<03:21,  1.08it/s]\u001b[A\n",
      " 52%|█████▏    | 235/451 [03:37<03:20,  1.08it/s]\u001b[A\n",
      " 52%|█████▏    | 236/451 [03:38<03:19,  1.08it/s]\u001b[A\n",
      " 53%|█████▎    | 237/451 [03:39<03:18,  1.08it/s]\u001b[A\n",
      " 53%|█████▎    | 238/451 [03:40<03:17,  1.08it/s]\u001b[A\n",
      " 53%|█████▎    | 239/451 [03:41<03:16,  1.08it/s]\u001b[A\n",
      " 53%|█████▎    | 240/451 [03:42<03:15,  1.08it/s]\u001b[A\n",
      " 53%|█████▎    | 241/451 [03:43<03:14,  1.08it/s]\u001b[A\n",
      " 54%|█████▎    | 242/451 [03:43<03:13,  1.08it/s]\u001b[A\n",
      " 54%|█████▍    | 243/451 [03:44<03:12,  1.08it/s]\u001b[A\n",
      " 54%|█████▍    | 244/451 [03:45<03:11,  1.08it/s]\u001b[A\n",
      " 54%|█████▍    | 245/451 [03:46<03:10,  1.08it/s]\u001b[A\n",
      " 55%|█████▍    | 246/451 [03:47<03:09,  1.08it/s]\u001b[A\n",
      " 55%|█████▍    | 247/451 [03:48<03:08,  1.08it/s]\u001b[A\n",
      " 55%|█████▍    | 248/451 [03:49<03:07,  1.08it/s]\u001b[A\n",
      " 55%|█████▌    | 249/451 [03:49<03:06,  1.08it/s]\u001b[A\n",
      " 55%|█████▌    | 250/451 [03:50<03:05,  1.08it/s]\u001b[A\n",
      " 56%|█████▌    | 251/451 [03:51<03:04,  1.08it/s]\u001b[A\n",
      " 56%|█████▌    | 252/451 [03:52<03:03,  1.08it/s]\u001b[A\n",
      " 56%|█████▌    | 253/451 [03:53<03:02,  1.08it/s]\u001b[A\n",
      " 56%|█████▋    | 254/451 [03:54<03:01,  1.09it/s]\u001b[A\n",
      " 57%|█████▋    | 255/451 [03:55<03:00,  1.08it/s]\u001b[A\n",
      " 57%|█████▋    | 256/451 [03:56<02:59,  1.08it/s]\u001b[A\n",
      " 57%|█████▋    | 257/451 [03:57<02:58,  1.08it/s]\u001b[A\n",
      " 57%|█████▋    | 258/451 [03:57<02:57,  1.08it/s]\u001b[A\n",
      " 57%|█████▋    | 259/451 [03:58<02:57,  1.08it/s]\u001b[A\n",
      " 58%|█████▊    | 260/451 [03:59<02:56,  1.08it/s]\u001b[A\n",
      " 58%|█████▊    | 261/451 [04:00<02:55,  1.08it/s]\u001b[A\n",
      " 58%|█████▊    | 262/451 [04:01<02:54,  1.09it/s]\u001b[A\n",
      " 58%|█████▊    | 263/451 [04:02<02:53,  1.09it/s]\u001b[A\n",
      " 59%|█████▊    | 264/451 [04:03<02:52,  1.09it/s]\u001b[A\n",
      " 59%|█████▉    | 265/451 [04:03<02:51,  1.09it/s]\u001b[A\n",
      " 59%|█████▉    | 266/451 [04:04<02:50,  1.09it/s]\u001b[A\n",
      " 59%|█████▉    | 267/451 [04:05<02:49,  1.09it/s]\u001b[A\n",
      " 59%|█████▉    | 268/451 [04:06<02:48,  1.09it/s]\u001b[A\n",
      " 60%|█████▉    | 269/451 [04:07<02:47,  1.09it/s]\u001b[A\n",
      " 60%|█████▉    | 270/451 [04:08<02:46,  1.09it/s]\u001b[A\n",
      " 60%|██████    | 271/451 [04:09<02:45,  1.09it/s]\u001b[A\n",
      " 60%|██████    | 272/451 [04:09<02:44,  1.09it/s]\u001b[A\n",
      " 61%|██████    | 273/451 [04:10<02:43,  1.09it/s]\u001b[A\n",
      " 61%|██████    | 274/451 [04:11<02:42,  1.09it/s]\u001b[A\n",
      " 61%|██████    | 275/451 [04:12<02:41,  1.09it/s]\u001b[A\n",
      " 61%|██████    | 276/451 [04:13<02:40,  1.09it/s]\u001b[A\n",
      " 61%|██████▏   | 277/451 [04:14<02:39,  1.09it/s]\u001b[A\n",
      " 62%|██████▏   | 278/451 [04:15<02:38,  1.09it/s]\u001b[A\n",
      " 62%|██████▏   | 279/451 [04:16<02:37,  1.09it/s]\u001b[A\n",
      " 62%|██████▏   | 280/451 [04:16<02:36,  1.09it/s]\u001b[A\n",
      " 62%|██████▏   | 281/451 [04:17<02:36,  1.09it/s]\u001b[A\n",
      " 63%|██████▎   | 282/451 [04:18<02:35,  1.09it/s]\u001b[A\n",
      " 63%|██████▎   | 283/451 [04:19<02:34,  1.09it/s]\u001b[A\n",
      " 63%|██████▎   | 284/451 [04:20<02:33,  1.09it/s]\u001b[A\n",
      " 63%|██████▎   | 285/451 [04:21<02:32,  1.09it/s]\u001b[A\n",
      " 63%|██████▎   | 286/451 [04:22<02:31,  1.09it/s]\u001b[A\n",
      " 64%|██████▎   | 287/451 [04:23<02:30,  1.09it/s]\u001b[A\n",
      " 64%|██████▍   | 288/451 [04:24<02:29,  1.09it/s]\u001b[A\n",
      " 64%|██████▍   | 289/451 [04:25<02:28,  1.09it/s]\u001b[A\n",
      " 64%|██████▍   | 290/451 [04:25<02:27,  1.09it/s]\u001b[A\n",
      " 65%|██████▍   | 291/451 [04:26<02:26,  1.09it/s]\u001b[A\n",
      " 65%|██████▍   | 292/451 [04:27<02:25,  1.09it/s]\u001b[A\n",
      " 65%|██████▍   | 293/451 [04:28<02:24,  1.09it/s]\u001b[A\n",
      " 65%|██████▌   | 294/451 [04:29<02:23,  1.09it/s]\u001b[A\n",
      " 65%|██████▌   | 295/451 [04:30<02:22,  1.09it/s]\u001b[A\n",
      " 66%|██████▌   | 296/451 [04:31<02:21,  1.09it/s]\u001b[A\n",
      " 66%|██████▌   | 297/451 [04:32<02:21,  1.09it/s]\u001b[A\n",
      " 66%|██████▌   | 298/451 [04:32<02:20,  1.09it/s]\u001b[A\n",
      " 66%|██████▋   | 299/451 [04:33<02:19,  1.09it/s]\u001b[A\n",
      " 67%|██████▋   | 300/451 [04:34<02:18,  1.09it/s]\u001b[A\n",
      " 67%|██████▋   | 301/451 [04:35<02:17,  1.09it/s]\u001b[A\n",
      " 67%|██████▋   | 302/451 [04:36<02:16,  1.09it/s]\u001b[A\n",
      " 67%|██████▋   | 303/451 [04:37<02:15,  1.09it/s]\u001b[A\n",
      " 67%|██████▋   | 304/451 [04:38<02:14,  1.09it/s]\u001b[A\n",
      " 68%|██████▊   | 305/451 [04:39<02:13,  1.09it/s]\u001b[A\n",
      " 68%|██████▊   | 306/451 [04:40<02:12,  1.09it/s]\u001b[A\n",
      " 68%|██████▊   | 307/451 [04:41<02:11,  1.09it/s]\u001b[A\n",
      " 68%|██████▊   | 308/451 [04:41<02:10,  1.09it/s]\u001b[A\n",
      " 69%|██████▊   | 309/451 [04:42<02:09,  1.09it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 310/451 [04:43<02:08,  1.09it/s]\u001b[A\n",
      " 69%|██████▉   | 311/451 [04:44<02:08,  1.09it/s]\u001b[A\n",
      " 69%|██████▉   | 312/451 [04:45<02:07,  1.09it/s]\u001b[A\n",
      " 69%|██████▉   | 313/451 [04:46<02:06,  1.09it/s]\u001b[A\n",
      " 70%|██████▉   | 314/451 [04:47<02:05,  1.09it/s]\u001b[A\n",
      " 70%|██████▉   | 315/451 [04:47<02:04,  1.09it/s]\u001b[A\n",
      " 70%|███████   | 316/451 [04:48<02:03,  1.09it/s]\u001b[A\n",
      " 70%|███████   | 317/451 [04:49<02:02,  1.09it/s]\u001b[A\n",
      " 71%|███████   | 318/451 [04:50<02:01,  1.09it/s]\u001b[A\n",
      " 71%|███████   | 319/451 [04:51<02:00,  1.10it/s]\u001b[A\n",
      " 71%|███████   | 320/451 [04:52<01:59,  1.10it/s]\u001b[A\n",
      " 71%|███████   | 321/451 [04:52<01:58,  1.10it/s]\u001b[A\n",
      " 71%|███████▏  | 322/451 [04:53<01:57,  1.10it/s]\u001b[A\n",
      " 72%|███████▏  | 323/451 [04:54<01:56,  1.10it/s]\u001b[A\n",
      " 72%|███████▏  | 324/451 [04:55<01:55,  1.10it/s]\u001b[A\n",
      " 72%|███████▏  | 325/451 [04:56<01:54,  1.10it/s]\u001b[A\n",
      " 72%|███████▏  | 326/451 [04:57<01:53,  1.10it/s]\u001b[A\n",
      " 73%|███████▎  | 327/451 [04:57<01:53,  1.10it/s]\u001b[A\n",
      " 73%|███████▎  | 328/451 [04:58<01:52,  1.10it/s]\u001b[A\n",
      " 73%|███████▎  | 329/451 [04:59<01:51,  1.10it/s]\u001b[A\n",
      " 73%|███████▎  | 330/451 [05:00<01:50,  1.10it/s]\u001b[A\n",
      " 73%|███████▎  | 331/451 [05:01<01:49,  1.10it/s]\u001b[A\n",
      " 74%|███████▎  | 332/451 [05:02<01:48,  1.10it/s]\u001b[A\n",
      " 74%|███████▍  | 333/451 [05:02<01:47,  1.10it/s]\u001b[A\n",
      " 74%|███████▍  | 334/451 [05:03<01:46,  1.10it/s]\u001b[A\n",
      " 74%|███████▍  | 335/451 [05:04<01:45,  1.10it/s]\u001b[A\n",
      " 75%|███████▍  | 336/451 [05:05<01:44,  1.10it/s]\u001b[A\n",
      " 75%|███████▍  | 337/451 [05:06<01:43,  1.10it/s]\u001b[A\n",
      " 75%|███████▍  | 338/451 [05:07<01:42,  1.10it/s]\u001b[A\n",
      " 75%|███████▌  | 339/451 [05:07<01:41,  1.10it/s]\u001b[A\n",
      " 75%|███████▌  | 340/451 [05:08<01:40,  1.10it/s]\u001b[A\n",
      " 76%|███████▌  | 341/451 [05:09<01:39,  1.10it/s]\u001b[A\n",
      " 76%|███████▌  | 342/451 [05:10<01:38,  1.10it/s]\u001b[A\n",
      " 76%|███████▌  | 343/451 [05:11<01:38,  1.10it/s]\u001b[A\n",
      " 76%|███████▋  | 344/451 [05:12<01:37,  1.10it/s]\u001b[A\n",
      " 76%|███████▋  | 345/451 [05:13<01:36,  1.10it/s]\u001b[A\n",
      " 77%|███████▋  | 346/451 [05:13<01:35,  1.10it/s]\u001b[A\n",
      " 77%|███████▋  | 347/451 [05:14<01:34,  1.10it/s]\u001b[A\n",
      " 77%|███████▋  | 348/451 [05:15<01:33,  1.10it/s]\u001b[A\n",
      " 77%|███████▋  | 349/451 [05:16<01:32,  1.10it/s]\u001b[A\n",
      " 78%|███████▊  | 350/451 [05:17<01:31,  1.10it/s]\u001b[A\n",
      " 78%|███████▊  | 351/451 [05:18<01:30,  1.10it/s]\u001b[A\n",
      " 78%|███████▊  | 352/451 [05:18<01:29,  1.10it/s]\u001b[A\n",
      " 78%|███████▊  | 353/451 [05:19<01:28,  1.10it/s]\u001b[A\n",
      " 78%|███████▊  | 354/451 [05:20<01:27,  1.10it/s]\u001b[A\n",
      " 79%|███████▊  | 355/451 [05:21<01:26,  1.10it/s]\u001b[A\n",
      " 79%|███████▉  | 356/451 [05:22<01:26,  1.10it/s]\u001b[A\n",
      " 79%|███████▉  | 357/451 [05:23<01:25,  1.10it/s]\u001b[A\n",
      " 79%|███████▉  | 358/451 [05:24<01:24,  1.10it/s]\u001b[A\n",
      " 80%|███████▉  | 359/451 [05:24<01:23,  1.11it/s]\u001b[A\n",
      " 80%|███████▉  | 360/451 [05:25<01:22,  1.11it/s]\u001b[A\n",
      " 80%|████████  | 361/451 [05:26<01:21,  1.11it/s]\u001b[A\n",
      " 80%|████████  | 362/451 [05:27<01:20,  1.11it/s]\u001b[A\n",
      " 80%|████████  | 363/451 [05:28<01:19,  1.11it/s]\u001b[A\n",
      " 81%|████████  | 364/451 [05:29<01:18,  1.11it/s]\u001b[A\n",
      " 81%|████████  | 365/451 [05:30<01:17,  1.11it/s]\u001b[A\n",
      " 81%|████████  | 366/451 [05:30<01:16,  1.11it/s]\u001b[A\n",
      " 81%|████████▏ | 367/451 [05:31<01:15,  1.11it/s]\u001b[A\n",
      " 82%|████████▏ | 368/451 [05:32<01:15,  1.11it/s]\u001b[A\n",
      " 82%|████████▏ | 369/451 [05:33<01:14,  1.11it/s]\u001b[A\n",
      " 82%|████████▏ | 370/451 [05:34<01:13,  1.11it/s]\u001b[A\n",
      " 82%|████████▏ | 371/451 [05:35<01:12,  1.11it/s]\u001b[A\n",
      " 82%|████████▏ | 372/451 [05:36<01:11,  1.11it/s]\u001b[A\n",
      " 83%|████████▎ | 373/451 [05:36<01:10,  1.11it/s]\u001b[A\n",
      " 83%|████████▎ | 374/451 [05:37<01:09,  1.11it/s]\u001b[A\n",
      " 83%|████████▎ | 375/451 [05:38<01:08,  1.11it/s]\u001b[A\n",
      " 83%|████████▎ | 376/451 [05:39<01:07,  1.11it/s]\u001b[A\n",
      " 84%|████████▎ | 377/451 [05:40<01:06,  1.11it/s]\u001b[A\n",
      " 84%|████████▍ | 378/451 [05:41<01:05,  1.11it/s]\u001b[A\n",
      " 84%|████████▍ | 379/451 [05:42<01:05,  1.11it/s]\u001b[A\n",
      " 84%|████████▍ | 380/451 [05:43<01:04,  1.11it/s]\u001b[A\n",
      " 84%|████████▍ | 381/451 [05:43<01:03,  1.11it/s]\u001b[A\n",
      " 85%|████████▍ | 382/451 [05:44<01:02,  1.11it/s]\u001b[A\n",
      " 85%|████████▍ | 383/451 [05:45<01:01,  1.11it/s]\u001b[A\n",
      " 85%|████████▌ | 384/451 [05:46<01:00,  1.11it/s]\u001b[A\n",
      " 85%|████████▌ | 385/451 [05:47<00:59,  1.11it/s]\u001b[A\n",
      " 86%|████████▌ | 386/451 [05:48<00:58,  1.11it/s]\u001b[A\n",
      " 86%|████████▌ | 387/451 [05:49<00:57,  1.11it/s]\u001b[A\n",
      " 86%|████████▌ | 388/451 [05:50<00:56,  1.11it/s]\u001b[A\n",
      " 86%|████████▋ | 389/451 [05:50<00:55,  1.11it/s]\u001b[A\n",
      " 86%|████████▋ | 390/451 [05:51<00:55,  1.11it/s]\u001b[A\n",
      " 87%|████████▋ | 391/451 [05:52<00:54,  1.11it/s]\u001b[A\n",
      " 87%|████████▋ | 392/451 [05:53<00:53,  1.11it/s]\u001b[A\n",
      " 87%|████████▋ | 393/451 [05:54<00:52,  1.11it/s]\u001b[A\n",
      " 87%|████████▋ | 394/451 [05:55<00:51,  1.11it/s]\u001b[A\n",
      " 88%|████████▊ | 395/451 [05:56<00:50,  1.11it/s]\u001b[A\n",
      " 88%|████████▊ | 396/451 [05:56<00:49,  1.11it/s]\u001b[A\n",
      " 88%|████████▊ | 397/451 [05:57<00:48,  1.11it/s]\u001b[A\n",
      " 88%|████████▊ | 398/451 [05:58<00:47,  1.11it/s]\u001b[A\n",
      " 88%|████████▊ | 399/451 [05:59<00:46,  1.11it/s]\u001b[A\n",
      " 89%|████████▊ | 400/451 [05:59<00:45,  1.11it/s]\u001b[A\n",
      " 89%|████████▉ | 401/451 [06:00<00:44,  1.11it/s]\u001b[A\n",
      " 89%|████████▉ | 402/451 [06:01<00:44,  1.11it/s]\u001b[A\n",
      " 89%|████████▉ | 403/451 [06:01<00:43,  1.11it/s]\u001b[A\n",
      " 90%|████████▉ | 404/451 [06:02<00:42,  1.11it/s]\u001b[A\n",
      " 90%|████████▉ | 405/451 [06:03<00:41,  1.11it/s]\u001b[A\n",
      " 90%|█████████ | 406/451 [06:04<00:40,  1.11it/s]\u001b[A\n",
      " 90%|█████████ | 407/451 [06:04<00:39,  1.12it/s]\u001b[A\n",
      " 90%|█████████ | 408/451 [06:05<00:38,  1.12it/s]\u001b[A\n",
      " 91%|█████████ | 409/451 [06:06<00:37,  1.12it/s]\u001b[A\n",
      " 91%|█████████ | 410/451 [06:07<00:36,  1.12it/s]\u001b[A\n",
      " 91%|█████████ | 411/451 [06:08<00:35,  1.12it/s]\u001b[A\n",
      " 91%|█████████▏| 412/451 [06:08<00:34,  1.12it/s]\u001b[A\n",
      " 92%|█████████▏| 413/451 [06:09<00:34,  1.12it/s]\u001b[A\n",
      " 92%|█████████▏| 414/451 [06:10<00:33,  1.12it/s]\u001b[A\n",
      " 92%|█████████▏| 415/451 [06:11<00:32,  1.12it/s]\u001b[A\n",
      " 92%|█████████▏| 416/451 [06:11<00:31,  1.12it/s]\u001b[A\n",
      " 92%|█████████▏| 417/451 [06:12<00:30,  1.12it/s]\u001b[A\n",
      " 93%|█████████▎| 418/451 [06:13<00:29,  1.12it/s]\u001b[A\n",
      " 93%|█████████▎| 419/451 [06:14<00:28,  1.12it/s]\u001b[A\n",
      " 93%|█████████▎| 420/451 [06:14<00:27,  1.12it/s]\u001b[A\n",
      " 93%|█████████▎| 421/451 [06:15<00:26,  1.12it/s]\u001b[A\n",
      " 94%|█████████▎| 422/451 [06:16<00:25,  1.12it/s]\u001b[A\n",
      " 94%|█████████▍| 423/451 [06:17<00:24,  1.12it/s]\u001b[A\n",
      " 94%|█████████▍| 424/451 [06:18<00:24,  1.12it/s]\u001b[A\n",
      " 94%|█████████▍| 425/451 [06:18<00:23,  1.12it/s]\u001b[A\n",
      " 94%|█████████▍| 426/451 [06:19<00:22,  1.12it/s]\u001b[A\n",
      " 95%|█████████▍| 427/451 [06:20<00:21,  1.12it/s]\u001b[A\n",
      " 95%|█████████▍| 428/451 [06:21<00:20,  1.12it/s]\u001b[A\n",
      " 95%|█████████▌| 429/451 [06:22<00:19,  1.12it/s]\u001b[A\n",
      " 95%|█████████▌| 430/451 [06:23<00:18,  1.12it/s]\u001b[A\n",
      " 96%|█████████▌| 431/451 [06:23<00:17,  1.12it/s]\u001b[A\n",
      " 96%|█████████▌| 432/451 [06:24<00:16,  1.12it/s]\u001b[A\n",
      " 96%|█████████▌| 433/451 [06:25<00:16,  1.12it/s]\u001b[A\n",
      " 96%|█████████▌| 434/451 [06:26<00:15,  1.12it/s]\u001b[A\n",
      " 96%|█████████▋| 435/451 [06:27<00:14,  1.12it/s]\u001b[A\n",
      " 97%|█████████▋| 436/451 [06:28<00:13,  1.12it/s]\u001b[A\n",
      " 97%|█████████▋| 437/451 [06:28<00:12,  1.12it/s]\u001b[A\n",
      " 97%|█████████▋| 438/451 [06:29<00:11,  1.12it/s]\u001b[A\n",
      " 97%|█████████▋| 439/451 [06:30<00:10,  1.12it/s]\u001b[A\n",
      " 98%|█████████▊| 440/451 [06:31<00:09,  1.12it/s]\u001b[A\n",
      " 98%|█████████▊| 441/451 [06:32<00:08,  1.12it/s]\u001b[A\n",
      " 98%|█████████▊| 442/451 [06:32<00:08,  1.12it/s]\u001b[A\n",
      " 98%|█████████▊| 443/451 [06:33<00:07,  1.13it/s]\u001b[A\n",
      " 98%|█████████▊| 444/451 [06:34<00:06,  1.13it/s]\u001b[A\n",
      " 99%|█████████▊| 445/451 [06:35<00:05,  1.13it/s]\u001b[A\n",
      " 99%|█████████▉| 446/451 [06:36<00:04,  1.13it/s]\u001b[A\n",
      " 99%|█████████▉| 447/451 [06:36<00:03,  1.13it/s]\u001b[A\n",
      " 99%|█████████▉| 448/451 [06:37<00:02,  1.13it/s]\u001b[A\n",
      "100%|█████████▉| 449/451 [06:38<00:01,  1.13it/s]\u001b[A\n",
      "100%|█████████▉| 450/451 [06:39<00:00,  1.13it/s]\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: Real_Car_Images_And_Videos/Bay_Area_Output_Videos/output.mp4 \n",
      "\n",
      "CPU times: user 23min 56s, sys: 2min 21s, total: 26min 17s\n",
      "Wall time: 6min 40s\n"
     ]
    }
   ],
   "source": [
    "# the region of interest that is between the lane lines that needs to be blacked out\n",
    "previous_warp_zero = None\n",
    "project_output = 'Real_Car_Images_And_Videos/Bay_Area_Output_Videos/output.mp4'\n",
    "clip1 = VideoFileClip(\"Real_Car_Images_And_Videos/Bay_Area_Videos/Highway_280_3-31-2018.mp4\").subclip(57,72);\n",
    "#clip1 = VideoFileClip(\"Real_Car_Images_And_Videos/Bay_Area_Videos/Highway_280_3-31-2018.mp4\");\n",
    "white_clip = clip1.fl_image(process_image) \n",
    "%time white_clip.write_videofile(project_output, audio = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
